{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Things to do\n",
    "- [x] Import images as separate directory\n",
    "- [ ] Use os to import the images rather than hard coding it\n",
    "- [x] Convertion of rgb to grayscale\n",
    "- [x] Cropping the image to only manipulation zone\n",
    "- [x] Resize of the image (Not required)\n",
    "- [x] K-means clustering\n",
    "- [ ] Extarct the major cluster points and try to change the color\n",
    "- [ ] Distance Transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the image: (480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/lil-e-va/Downloads/ML_project/ml_project/lib/python3.10/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "# Importing the image and visualizing it.\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "image = cv2.imread(\"/home/lil-e-va/Downloads/ML_project/empty_-_detection_ML/data/image_003.jpg\",0)\n",
    "print(f'The size of the image: {image.shape}')\n",
    "\n",
    "# Creating the dataframe\n",
    "dataframe_image = pd.DataFrame(image)\n",
    "dataframe_image.to_csv(\"/home/lil-e-va/Downloads/ML_project/empty_-_detection_ML/data/Image_values.csv\")\n",
    "\n",
    "cv2.imshow('Original',image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(260, 610)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Cropping the image\n",
    "ref - https://learnopencv.com/cropping-an-image-using-opencv/\n",
    "'''\n",
    "\n",
    "cropped_image = image[150:410,30:640]\n",
    "print(cropped_image.shape)\n",
    "cv2.imshow(\"cropped\", cropped_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Trying to change the a particular color of the pixels to other colors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized Image shape :(158600, 3)\n",
      "Number of pixels r values that changed to zero: 84007\n",
      "Number of pixels g values that changed to zero: 84007\n",
      "Number of pixels b values that changed to zero: 84007\n",
      "Needs to be changed: 252021\n",
      "Vectorized Image values :\n",
      "[[ 44  44  44]\n",
      " [ 51  51  51]\n",
      " [ 94  94  94]\n",
      " ...\n",
      " [  0 128   0]\n",
      " [  0 128   0]\n",
      " [  0 128   0]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "To pick the color values from the image the following website was used.\n",
    "ref - https://imagecolorpicker.com/\n",
    "\n",
    "Upload your image and use the eyedropper to find the color of that particular pixel.\n",
    "o/p -> 150,150,150 to 185,185,185 are the free space areas from the manipulation we are going to color that.\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.cvtColor(cropped_image,cv2.COLOR_BGR2RGB)\n",
    "vectorized = img.reshape((-1,3))\n",
    "# print(f'Vectorized Image values :{vectorized}')\n",
    "print(f'Vectorized Image shape :{vectorized.shape}')\n",
    "\n",
    "# Below code is to understand the number of the rows which are accessible.\n",
    "\n",
    "count_rows = 0\n",
    "count_changed_r = 0\n",
    "count_changed_g = 0\n",
    "count_changed_b = 0\n",
    "count_r = 0\n",
    "count_g = 0\n",
    "count_b = 0\n",
    "count_b_w_range =0\n",
    "\n",
    "for j in range (0,3):\n",
    "    for i,value in enumerate(vectorized[:,j]):\n",
    "        count_rows+=1\n",
    "        # print(f'index: {i}')\n",
    "        # print(f'value: {value}')\n",
    "        if j==0:\n",
    "            count_r+=1\n",
    "            if 149<value<186:\n",
    "                count_changed_r+=1    \n",
    "                vectorized[i,j]=0\n",
    "        elif j==1:\n",
    "            count_g+=1\n",
    "            if 149<value<186:\n",
    "                count_changed_g+=1\n",
    "                vectorized[i,j]=128\n",
    "        else:\n",
    "            count_b+=1\n",
    "            if 149<value<186:\n",
    "                count_changed_b+=1\n",
    "                vectorized[i,j]=0\n",
    "        if 149<value<186:\n",
    "            # print(f'value satisfies the conditions are: {value}')\n",
    "            count_b_w_range+=1\n",
    "\n",
    "# print(f'rows: {count_rows}')\n",
    "# print(f'Number of pixels r: {count_r}')\n",
    "# print(f'Number of pixels g: {count_g}')\n",
    "# print(f'Number of pixels b: {count_b}')\n",
    "print(f'Number of pixels r values that changed to zero: {count_changed_r}')\n",
    "print(f'Number of pixels g values that changed to zero: {count_changed_g}')\n",
    "print(f'Number of pixels b values that changed to zero: {count_changed_b}')\n",
    "print(f'Needs to be changed: {count_b_w_range}')\n",
    "\n",
    "print(f'Vectorized Image values :\\n{vectorized}')\n",
    "\n",
    "vectorized = np.uint8(vectorized)\n",
    "vectorized.flatten()    \n",
    "result_image = vectorized.reshape((img.shape)) # It has to be reshapped to the inital image format thats when the image will be shown properly\n",
    "\n",
    "cv2.imshow(\"color_change\", result_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is it a wise option to resize the image??? Use Cropped Image for now.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Resizing the image\n",
    "ref - https://learnopencv.com/image-resizing-with-opencv/\n",
    "'''\n",
    "\n",
    "downscale_val = (256,256)\n",
    "imgresized = cv2.resize(cropped_image,downscale_val,interpolation=cv2.INTER_AREA)\n",
    "\n",
    "print(imgresized.shape)\n",
    "cv2.imshow('resize_image',imgresized)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Image Segmentation with K-means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Image Segmentation with Kmeans\n",
    "ref - https://www.kaggle.com/code/hal1001k/image-segmentation-with-kmeans\n",
    "'''\n",
    "\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Converting 3D image into numpy array to 2D\n",
    "'''\n",
    "\n",
    "# img = cv2.cvtColor(imgresized,cv2.COLOR_BGR2RGB)\n",
    "img = cv2.cvtColor(cropped_image,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "print(f'img; {img.shape}')\n",
    "r,g,b = cv2.split(img)\n",
    "\n",
    "r = r.flatten()\n",
    "g = g.flatten()\n",
    "b = b.flatten()\n",
    "\n",
    "print(f'r: {r}')\n",
    "# print(f'g: {g}')\n",
    "# print(f'b: {b}')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111,projection='3d')\n",
    "# ax.scatter(r,g,b)\n",
    "ax.scatter(r, g, b)\n",
    "ax.set_xlabel('Red')\n",
    "ax.set_ylabel('Green')\n",
    "ax.set_zlabel('Blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Reshaping np array in 2D to perform kmeans_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "kmeans - Clustering\n",
    "ref - https://opencv24-python-tutorials.readthedocs.io/en/latest/py_tutorials/py_ml/py_kmeans/py_kmeans_opencv/py_kmeans_opencv.html#kmeans-opencv\n",
    "\n",
    "flatten() - return a copy of a given array in such a way that it is collapsed into one dimension.\n",
    "\n",
    "'''\n",
    "\n",
    "vectorized = img.reshape((-1,3))\n",
    "# print(f'vectorized: {vectorized.shape}')\n",
    "vectorized = np.float32(vectorized)\n",
    "print(f'vectorized: {vectorized}')\n",
    "\n",
    "\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "K = 3\n",
    "attempts = 10\n",
    "ret,label,center=cv2.kmeans(vectorized,K,None,criteria,attempts,cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "\n",
    "# # Created to check the label values\n",
    "# label_dict = pd.DataFrame(label)\n",
    "# label_dict.to_csv('/home/lil-e-va/Downloads/ML_project/empty_-_detection_ML/data/label_data')\n",
    "\n",
    "label = label.flatten()\n",
    "print(f'{label}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visulaizing the labels using scatter plot\n",
    "\n",
    "count_0 = 0\n",
    "count_1 = 0\n",
    "count_2 = 0\n",
    "label_0 = []\n",
    "label_1 = []\n",
    "label_2 = []\n",
    "for lab in label:\n",
    "    if lab == 0:\n",
    "        count_0+=1\n",
    "        label_0.append(lab)\n",
    "\n",
    "    elif lab ==1:\n",
    "        count_1+=1\n",
    "        label_1.append(lab)\n",
    "    else:\n",
    "        count_2+=1\n",
    "        label_2.append(lab)\n",
    "\n",
    "print(f'Label 0 is in nos: {count_0}')\n",
    "# print(f'Label 0: {len(label_0)}')\n",
    "print(f'Label 1 is in nos: {count_1}')\n",
    "# print(f'Label 1: {len(label_1)}')\n",
    "print(f'Label 2 is in nos: {count_2}')\n",
    "# print(f'Label 2: {len(label_2)}')\n",
    "print(f'center: \\n{center}')\n",
    "\n",
    "print(f'\\n\\n Label_0 value: {label_0}')\n",
    "print(f'\\n\\n Label_1 value: {label_1}')\n",
    "print(f'\\n\\n Label_2 value: {label_2}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center = np.uint8(center)\n",
    "res = center[label.flatten()]\n",
    "result_image = res.reshape((img.shape))\n",
    "\n",
    "plt.imshow(result_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Comparing Original and Segmented Image_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_size = 10\n",
    "plt.figure(figsize=(figure_size,figure_size))\n",
    "plt.subplot(1, 2, 1),plt.imshow(img)\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1, 2, 2),plt.imshow(result_image)\n",
    "plt.title('Segmented Image when K = %i' % K), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = cv2.Canny(img,150,200)\n",
    "plt.figure(figsize=(figure_size,figure_size))\n",
    "plt.subplot(1,2,1),plt.imshow(img)\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(1,2,2),plt.imshow(edges,cmap = 'gray')\n",
    "plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the following code to use the distance Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB)\n",
    "image = image.reshape((image.shape[0] * image.shape[1], 3))\n",
    "\n",
    "clt = KMeans(n_clusters = 5)\n",
    "clt.fit(image)\n",
    "\n",
    "def centroid_histogram(clt):\n",
    "\t# grab the number of different clusters and create a histogram\n",
    "\t# based on the number of pixels assigned to each cluster\n",
    "\tnumLabels = np.arange(0, len(np.unique(clt.labels_)) + 1)\n",
    "\t(hist, _) = np.histogram(clt.labels_, bins = numLabels)\n",
    "\t# normalize the histogram, such that it sums to one\n",
    "\thist = hist.astype(\"float\")\n",
    "\thist /= hist.sum()\n",
    "\t# return the histogram\n",
    "\treturn hist\n",
    "\n",
    "def plot_colors(hist, centroids):\n",
    "\t# initialize the bar chart representing the relative frequency\n",
    "\t# of each of the colors\n",
    "\tbar = np.zeros((50, 300, 3), dtype = \"uint8\")\n",
    "\tstartX = 0\n",
    "\t# loop over the percentage of each cluster and the color of\n",
    "\t# each cluster\n",
    "\tfor (percent, color) in zip(hist, centroids):\n",
    "\t\t# plot the relative percentage of each cluster\n",
    "\t\tendX = startX + (percent * 300)\n",
    "\t\tcv2.rectangle(bar, (int(startX), 0), (int(endX), 50),\n",
    "\t\t\tcolor.astype(\"uint8\").tolist(), -1)\n",
    "\t\tstartX = endX\n",
    "\t\n",
    "\t# return the bar chart\n",
    "\treturn bar\n",
    "\n",
    "hist = centroid_histogram(clt)\n",
    "bar = plot_colors(hist, clt.cluster_centers_)\n",
    "# show our color bart\n",
    "plt.figure()\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(bar)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
